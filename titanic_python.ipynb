{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic_Python.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Titanic-Start",
        "colab_type": "text"
      },
      "source": [
        "###Titanic Python\n",
        "\n",
        "1/May/2019\n",
        "\n",
        "*\"first catch your hare\"*\n",
        "\n",
        "In our terms get the data and understand the objective. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Start-Code",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b34a45e-9db6-4a6c-dfae-8a0d63a9567d"
      },
      "source": [
        "# simple statment to confirm that the notebook processing is active\n",
        "# for Google colab - it often takes a few seconds to get things started \n",
        "# this simple step with its clear output provides a visual check\n",
        "print (\"Titanic - Python\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Titanic - Python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlvtwczK25f-",
        "colab_type": "text"
      },
      "source": [
        "### Imports\n",
        "\n",
        "One of the strengths of Python is the range of external libraries which can be used.\n",
        "\n",
        "An important mathematical library - which implements multidimensional arrays and many methods for manipulating them is numpy - which by convention we import as 'np'.  \n",
        "\n",
        "For data analysis there is an important library called pandas which implements a dataframe which can be used to store tabular data and implements many useful methods for manipulating these dataframes - by convention we import it as 'pd'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP-t4wSIVHYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YISzxq-xJz3F",
        "colab_type": "text"
      },
      "source": [
        "Import data from Google drive : \n",
        "\n",
        "For the next section of code to work you have to have copied the relevant files to your\n",
        "Google Drive.\n",
        "\n",
        "And as far as I know it only works from Google Colab - which is where I created this notebook.\n",
        "\n",
        "I have commented the code to prevent it running and generating an error if the Google Drive link is \n",
        "not in place -  it requires a Google Drive authorisation every session.\n",
        "\n",
        "Clearly if you uncomment and use this code then you need to skip or comment out the next section.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e4uiXXgVJV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "# !ls /content/gdrive\n",
        "# !ls -l /content/gdrive/My\\ Drive\n",
        "# !ls -l /content/gdrive/My\\ Drive/Colab\\ Notebooks\n",
        "# !ls -l /content/gdrive/My\\ Drive/Colab\\ Notebooks/Titanic\n",
        "\n",
        "# titanic_known = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Titanic/titanic_known.csv')\n",
        "# print (titanic_known.describe())\n",
        "# titanic_unknown = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Titanic/titanic_unknown.csv')\n",
        "# print (titanic_unknown.describe())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R52r5Hy6K6nj",
        "colab_type": "text"
      },
      "source": [
        "Import data from a web source\n",
        "\n",
        "Pandas dataframes have a read_cvs method for reading csv sources - there are other simlar methods for reading different format sources all of which can take a web URL as the location as well as a local file.\n",
        "\n",
        "The below is a simple load directly from a web source - which is fine for small datasets but not recommended if the amount of data gets large.\n",
        "\n",
        "Any webserver will work.\n",
        "\n",
        "I use github to store my working code - you can access files in a github repository directly using the raw.githubusercontent.com/*username*/. . . address. \n",
        "\n",
        "Github also provides a 'special' repository name of *username*.github.io to allow you to create a repository which works as a static webserver (i.e. no server-side processing) - and this is perfectly serviceable for loading data into an object using the pandas read_csv method.\n",
        "\n",
        "After reading file into a pandas dateframe we use len to get the number of rows and the we use the datframe method count to get the number of entries in each collum - and the collum names - this is pretty much a  *'have I got the data I expect?'*  verification.  And it gives us some basic insight into our data.\n",
        "\n",
        "Whereas the whole purpose of using a machine to analyse data is to avoid much of the associated drudge work - it is hugely beneficial to have a good understanding of the data itself - particularly important is to make sure that the meaning of data is precise - for example, in this case we will have cause to ask what exactly does the Fare column contain.  And the asnwer to that question gives us an additional piece of data that we don't know that we have at the moment and that improves the performance of some of our models.\n",
        "\n",
        "To this end we will spend a bit of time just looking at the data in various ways."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhlDUtf0IPtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "titanic_known = pd.read_csv(\"https://raw.githubusercontent.com/johnsl01/Titanic_Python/master/titanic_known.csv\", sep=\",\")\n",
        "\n",
        "# titanic_known = pd.read_csv(\"https://johnsl01.github.io/titanic/titanic_known.csv\", sep=\",\")\n",
        "print (\"Known :\")\n",
        "print (str(len(titanic_known)) + \" Rows\")\n",
        "print (titanic_known.count())\n",
        "\n",
        "titanic_unknown = pd.read_csv(\"https://johnsl01.github.io/titanic/titanic_unknown.csv\", sep=\",\")\n",
        "print (\"\\nUnknown :\") \n",
        "print (str(len(titanic_unknown)) + \" Rows\")\n",
        "print (titanic_unknown.count())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd09C_DDhQAe",
        "colab_type": "text"
      },
      "source": [
        "#### head and tail\n",
        "\n",
        "Our data is a bit unreal at the moment - we know the column names and the count of data in each - and we know that some ages and a lot of cabins are missing.\n",
        "\n",
        "And we know that the 'known' dataframe has an extra column; 'Survived' which we expect to tell us what the fate of that passenger was - which is obviously missing from the 'unknown' dataframe.\n",
        "\n",
        "One of the simplest things to do with data is to inspect it row by row and the starting point in this is usually to use the head and tail methods.  Head and tail derive from two unix commands which appeared very early in unix - and were used to show the first and last lines in a file.  By default they returned 5 lines and this default has persisted for almost 50 years as they are reincarnated in different systems.\n",
        "\n",
        "So pandas dataframes have a head and a tail method which do the same for dataframe rows : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3ggUQwWhQkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"Known : -  first 5 and last 2:\")\n",
        "print (titanic_known.head())\n",
        "print (titanic_known.tail(2))\n",
        "\n",
        "print (\"UnkKnown : -  first 5 and last 2:\")\n",
        "print (titanic_unknown.head())\n",
        "print (titanic_unknown.tail(2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T56ZUrexkHZs",
        "colab_type": "text"
      },
      "source": [
        "OK - so this tells us someting and also raises some concerns.\n",
        "\n",
        "The encoding of the survived column is 1 and 0  (1 for survived and 0 for died) - this is the most common numeric for a boolean value - 'Y' and 'N' and 'T' and 'F' being the most common character encodings - it is important to be sure that we get the mapping correct.  \n",
        "\n",
        "The Pclass column is the passenger class - the ship was divided into three different classes - 1st, 2nd and 3rd.  1st class passengers had luxurious cabins, they had open access to the upper decks and to the luxurious 'state' rooms of the ship - they were generally wealthier and as well as some having brought personal staff with them they had a lot of the ship's crew dedicated to their care.  We should expect that this will be a factor in survival - access and crew deference being significant factors. 2nd class had individual cabins but less deck access and restricted access to some areas.  3rd class passengers generally were below decks - had dormitory type accomodation and were packed in pretty tight - they did not have much deck access and were unable to get into much of the 1st and 2nd class areas.\n",
        "\n",
        "The name is the passenger's name and includes a title Mr. Mrs. etc as well as maiden names for married women.  This is text data so while we will want to make use of it we have to be careful in how we processes it - we will definitely want to pull out the title as that will help us in some cases with filling in the missing ages - and we will make some use of the name information to try and derive some information to help us with understanding what size of a party each passenger was likely in.\n",
        "\n",
        "Sex is text and is either 'male' or 'female'.  Any knowledge of the history of the titanic will likely include the phrase 'women and children first'.  We should expect that it is probably a factor in survival - and we can validate it pretty quickly.\n",
        "\n",
        "Age is self explanatory - it has a lot of missing values - we will look at mechanisms for filling in these values from the rest of the data, we expect that age will be a factor in survival - but need to explore how it affects it - expectation is probably that the elderly may have been less likely to survive - but despite being less able we expect the young may have survived both from having an adult caring for them and from the 'women and children first' policy - which is as yet unvalidated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxGMJiksbNo0",
        "colab_type": "text"
      },
      "source": [
        "Lets look at our spread of values in the numeric columns using the describe method.\n",
        "\n",
        "The PassengerID is just an incrementing counter which runs continuously from the knowns 1 through 891 and the unknowns (892 through 1309) - so the numerical analysis is pretty meaningless.\n",
        "\n",
        "The counts are the same as above, the missing values in the ages column are clear."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU3gwsE2bOZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"Known :\")\n",
        "print (titanic_known.describe())\n",
        "print (\"\\nUnknown :\") \n",
        "print (titanic_unknown.describe())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQlKNxRVY6eG",
        "colab_type": "text"
      },
      "source": [
        "We have two groups of passengers - before we do anything with the data let's just check that the two sets are reasonably comparable.  By looking a a simple correlation matrix between the numeric collumns we should be able to see if the two groups are basically similar.\n",
        "\n",
        "We'll just run the correlation for the selected numeric columns - and we'll skip the 'Survived' column for the moment.  \n",
        "\n",
        "Clearly the Survived column's correlation with the other data is key to what we are trying to do - so we will focus on it when we have completed our exploration of the basic data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAGLolz5Yigg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"Known :\")\n",
        "print (titanic_known[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']].corr())\n",
        "print (\"\\nUnknown :\") \n",
        "print (titanic_unknown[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']].corr())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oVbrmDYaGOf",
        "colab_type": "text"
      },
      "source": [
        "This shows that our two groups are somewhat similar - but we have only looked at the numeric values.  This correlation ignores all the missing numeric values - and we know that a lot of ages are missing - a simple way to extend this analysis would be to encode gender and embarkation as integers and this would give us some additional information.\n",
        "\n",
        "However we will be doing this anyway at a later stage so we can look at the revised correlation then.  The purpose of this exercise is just familiarity with the data.\n",
        "\n"
      ]
    }
  ]
}